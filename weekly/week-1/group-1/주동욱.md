# GitHub Flow 요약 

GitHub Flow는 협업에 정말 잘 맞는 간단한 브랜치 기반 워크플로이다. 개인 프로젝트보단, 여러 명이 참여하는 오픈소스 프로젝트나 팀 개발에서 훨씬 빛을 발하는 것 같다. 실습하면서 느낀 건 생각보다 쉽지만, 깔끔하게 지키는 게 중요하다는 점!

---

## ✅ 사전 준비

- GitHub 계정
- 원격 저장소(repository) 하나 만들기

이건 GitHub 사용법 중 기초니까 한 번쯤 다 해봤을 거다. 중요한 건 브랜치를 적극적으로 쓰는 거라고 느꼈음.

---

## 🔁 GitHub Flow 주요 단계

### 1. 브랜치 생성

- `main` 브랜치에서 새로운 브랜치 생성  
  예: `feature/login-ui`, `fix/readme-typo`
- 브랜치 이름은 작업 내용을 짐작할 수 있도록 구체적으로 짓는 게 좋다

```bash
git checkout -b feature/login-ui
```

 **내 생각**: 나는 보통 브랜치를 `issue 번호 + 간단한 설명`으로 짓는다. 예: `#12-fix-bug`  
이렇게 하면 나중에 PR 만들 때 이슈랑 연결하기도 쉽고, 브랜치만 봐도 무슨 작업인지 감이 옴.

---

### 2. 변경 사항 작업 및 커밋

```bash
git add .
git commit -m "Add login page layout"
git push origin feature/login-ui
```

- 커밋 메시지는 꼭 의미 있게 작성하기!
- 관련 없는 기능은 다른 브랜치에서 따로 작업하는 게 깔끔함

 **내 생각**: 커밋 메시지는 나중에 PR을 리뷰하거나 디버깅할 때 진짜 중요하다.  
한 줄이라도 "왜 이 커밋이 필요한가"가 드러나게 쓰는 습관 들이는 중.

---

### 3. Pull Request 생성

- GitHub에서 PR 생성
- 가능하면 draft로 먼저 만들어서 중간 진행 상황 공유도 가능
- PR 설명에는 **왜** 이 변경이 필요한지를 잘 쓰는 게 핵심

 **내 생각**: PR 메시지에 그냥 "작업 완료"만 쓰지 말고, 관련 이슈 번호, 주요 변경 사항 요약, 리뷰어가 체크할 포인트를 쓰면 서로 시간 아낄 수 있음.

---

### 4. 코드 리뷰 & 피드백 반영

- 다른 사람이 코드 리뷰
- 피드백 반영해서 커밋 추가
- PR은 자동으로 갱신됨

 **내 생각**: 처음엔 리뷰받는 게 무서웠는데 익숙해지니까 재밌기도 하다.  
리뷰는 나의 실수를 줄여주는 안전장치라고 생각하고 감사하게 받아들이게 됨.

---

### 5. 브랜치 병합

- 리뷰가 끝나면 `main` 브랜치에 merge
- 브랜치는 삭제해도 괜찮음

```bash
git checkout main
git pull origin main
git merge feature/login-ui
git push origin main
```

 **내 생각**: Merge 전에 꼭 한 번 `main` 최신 상태로 rebase 해보는 습관이 좋다.  
충돌 덜 나고 기록도 깔끔함.

---

### 6. 배포 (필요할 경우)

- GitHub Actions 같은 CI/CD 자동 배포 도구와 연계 가능

**내 생각**: Actions랑 연동해서 PR merge하면 자동으로 배포되게 해두면 진짜 편함.  
무중단 배포 연습할 때 엄청 유용했음.

---

## 📌 정리하며 느낀 점

| 단계 | 내 요약 |
|------|---------|
| 브랜치 생성 | 기능 단위로 작업을 분리함 |
| 변경 작업 & 커밋 | 세분화된 커밋, 의미 있는 메시지 |
| PR 생성 | 협업의 시작, 투명한 기록 |
| 리뷰 & 반영 | 협업의 핵심, 코드 품질 향상 |
| 병합 | main 브랜치에 반영 |
| 배포 | Actions로 자동화하면 최고 |

---

📚 [공식 문서 보기](https://docs.github.com/en/get-started/using-github/github-flow)

---

# 📘 대형 언어 모델(LLM)과 ChatGPT의 작동 원리  
> 🎥 유튜브 강의 보고 스스로 공부한 내용 정리  
---

## 🧠 1. LLM이란? 무엇을 위한 도구인가?

- LLM은 **Large Language Model**, 말 그대로 "거대한 언어 모델"이다.
- GPT, Claude, Gemini 같은 것들이 여기에 포함됨.
- 핵심은 **"다음에 올 말을 예측"**하는 능력.  
  → 생각보다 단순한 원리인데, 엄청난 계산 능력을 통해 놀라운 결과를 냄.

---

## ⚙️ 2. LLM은 어떻게 만들어지는가?

### 📌 1) 사전 훈련 (Pre-training)

| 단계 | 설명 |
|------|------|
| 데이터 수집 | 인터넷 웹사이트, 위키피디아 등에서 텍스트 수집 |
| 정제 작업 | 쓰레기 정보 제거, 중복 제거, 언어 필터링 등 |
| 토크나이징 | 문장을 작은 조각(토큰)으로 쪼갬 |
| 모델 학습 | 다음에 나올 토큰 예측을 목표로 학습 진행 |

- 데이터는 44TB 이상, 15조 개의 토큰 사용
- 주로 **BPE (Byte Pair Encoding)** 방식의 토크나이저 사용

### 📌 2) 내부 구조 - Transformer

- 입력: 토큰 시퀀스
- 출력: 다음 토큰의 확률 분포
- → 문장을 토큰 단위로 예측하는 방식

---

## 💬 3. Base Model vs Assistant Model

| Base Model | Assistant Model |
|------------|-----------------|
| 순수 예측기 | 사용자 요청에 맞춰 대화 응답 |
| 인터넷 텍스트 생성에 가까움 | 맥락 이해 + 유용한 응답 생성 |
| Prompt만 주면 대답은 가능하지만 어딘가 이상할 수 있음 | 예의 바르고 유용한 응답 생성 |

- Base 모델을 사람처럼 응답하게 하려면 **추가 훈련이 필요함**

---

## 🧪 4. 후속 훈련(Post-training)

### ✅ 지도학습 (SFT)

- 사람이 만든 질문-답변 데이터로 학습
- 라벨러가 작성한 “좋은 답변”을 따라하도록 모델을 훈련

### ✅ RLHF (Reinforcement Learning from Human Feedback)

- 사람이 둘 중 좋은 답을 선택 → 이를 기준으로 Reward Model 학습
- 그 Reward Model을 기준으로 모델을 다시 강화학습

---

## 🔁 5. 실제 사용: Inference (추론)

- 입력을 토큰화 → 모델을 통해 다음 토큰 반복 생성 → 다시 문장으로 디코딩
- 실시간 대화 같지만 사실은 “다음 단어 예측”의 반복

---

## 🔍 6. LLM이 흥미로운 이유

- GPT는 인터넷을 **통계적으로 압축한 모델**
- “지식”이라기보다는 **확률적으로 말의 흐름을 잘 이어가는 것**
- 결국 우리는 **라벨러의 행동을 흉내내는 시뮬레이터**와 대화하는 셈

---

## 🧠 7. 사고 모델 vs SFT 모델

- **사고 모델 (Reasoning Model)**: 실제 사고 과정을 강화학습으로 훈련 (예: DeepSeek, GPT-O3)
- **SFT 모델**: 대화형 스타일만 훈련 (예: GPT-4, GPT-4 Mini)
- 복잡한 문제(수학, 코딩 등)는 사고 모델이 유리함

---

## ♟️ 8. RL의 힘: AlphaGo 예시

- 인간을 모방하는 학습은 한계가 있음
- RL은 인간을 넘어서는 전략을 발견 가능 (예: AlphaGo의 Move 37)
- LLM에서도 **자가 플레이를 통한 사고력 향상** 가능성

---

## 🧠 9. RLHF의 메커니즘과 한계

- 인간의 평가를 흉내 낸 **Reward Model**을 기준으로 강화학습
- 문제: 오래 학습하면 말도 안 되는 답변이 최고 점수 받는 경우 발생 (예: "the the the")
- RLHF는 실제 RL이라기보다는 **세심한 미세조정에 가깝다**

---

## 🔮 10. LLM의 미래

- **멀티모달**: 이미지, 음성, 영상 처리까지 통합
- **에이전트화**: 사용자 대신 작업 수행
- **도구 활용**: 웹브라우저, 파일, 코드 실행 등
- **Test-time Learning**: 실행 중에도 학습 가능한 모델 연구 진행 중
- **컨텍스트 한계 극복**: 더 긴 문맥 처리 or 외부 메모리 연동 등 시도

---

## 💡 11. 모델 비교 및 실습 플랫폼

| 항목 | 예시 |
|------|------|
| 상용 모델 | ChatGPT (OpenAI), Gemini (Google) |
| 오픈소스 | DeepSeek, LLaMA3 등 |
| 사용처 | [GPTOnline.ai](https://gptonline.ai/ko/), [Together.ai](https://together.ai) |
| 로컬 실행 | LM Studio (distill 모델 사용 시 가능) |

---

## ✅ 마무리하며

지금 우리가 대화하고 있는 이 모델은 단순한 챗봇이 아니라,  
**수십억 개의 데이터와 강화학습을 거친 신경망 시뮬레이터**이다.
특히 사고 모델은 기존 인간 사고를 넘는 새로운 전략까지 만들어낼 수 있다는 점에서  
AI의 다음 가능성을 열어주고 있다.

🧑‍💻 공부하면서 느낀 건:  
- “말을 예쁘게 이어붙이는 기술”처럼 보이지만  
- **그 안엔 복잡한 수학, 통계, 학습 이론이 녹아 있다**는 점이다.

